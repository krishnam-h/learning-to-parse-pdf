{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flash.image import SemanticSegmentation\n",
    "from flash.image import SemanticSegmentationData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from flash import Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 'efficientnet-b0' provided by qubvel/segmentation_models.pytorch (https://github.com/qubvel/segmentation_models.pytorch).\n",
      "Using 'unet' provided by qubvel/segmentation_models.pytorch (https://github.com/qubvel/segmentation_models.pytorch).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = SemanticSegmentation.load_from_checkpoint(r\"E:\\Google Drive\\Acads\\Notes\\final sem\\ML\\project\\learning-to-parse-pdf\\documentAnalysis\\flash\\semantic_segmentation_model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pveen\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:133: UserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting:   5%|▍         | 1/21 [00:04<01:28,  4.43s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pveen\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\nn\\functional.py:3613: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 21/21 [00:08<00:00,  2.58it/s]\n"
     ]
    }
   ],
   "source": [
    "dm = SemanticSegmentationData.from_folders(\n",
    "    predict_folder=r\"E:\\Google Drive\\Acads\\Notes\\final sem\\ML\\project\\learning-to-parse-pdf\\documentAnalysis\\data\\images/\",\n",
    "    transform_kwargs=dict(image_size=(800, 640)),\n",
    "    batch_size = 1,\n",
    "    )\n",
    "trainer = Trainer(max_epochs=1, gpus = 1)\n",
    "predictions = trainer.predict(model, dm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images 21\n",
      "{'size': [792, 601], 'filepath': 'E:\\\\Google Drive\\\\Acads\\\\Notes\\\\final sem\\\\ML\\\\project\\\\learning-to-parse-pdf\\\\documentAnalysis\\\\data\\\\images/PMC3576793_00004.jpg'}\n",
      "{'size': [792, 601], 'filepath': 'E:\\\\Google Drive\\\\Acads\\\\Notes\\\\final sem\\\\ML\\\\project\\\\learning-to-parse-pdf\\\\documentAnalysis\\\\data\\\\images/PMC3654277_00006.jpg'}\n",
      "{'size': [794, 596], 'filepath': 'E:\\\\Google Drive\\\\Acads\\\\Notes\\\\final sem\\\\ML\\\\project\\\\learning-to-parse-pdf\\\\documentAnalysis\\\\data\\\\images/PMC3777717_00006.jpg'}\n",
      "{'size': [792, 601], 'filepath': 'E:\\\\Google Drive\\\\Acads\\\\Notes\\\\final sem\\\\ML\\\\project\\\\learning-to-parse-pdf\\\\documentAnalysis\\\\data\\\\images/PMC3863500_00003.jpg'}\n",
      "{'size': [792, 612], 'filepath': 'E:\\\\Google Drive\\\\Acads\\\\Notes\\\\final sem\\\\ML\\\\project\\\\learning-to-parse-pdf\\\\documentAnalysis\\\\data\\\\images/PMC3866684_00003.jpg'}\n",
      "{'size': [792, 601], 'filepath': 'E:\\\\Google Drive\\\\Acads\\\\Notes\\\\final sem\\\\ML\\\\project\\\\learning-to-parse-pdf\\\\documentAnalysis\\\\data\\\\images/PMC3976938_00002.jpg'}\n",
      "{'size': [842, 596], 'filepath': 'E:\\\\Google Drive\\\\Acads\\\\Notes\\\\final sem\\\\ML\\\\project\\\\learning-to-parse-pdf\\\\documentAnalysis\\\\data\\\\images/PMC4027932_00001.jpg'}\n",
      "{'size': [794, 596], 'filepath': 'E:\\\\Google Drive\\\\Acads\\\\Notes\\\\final sem\\\\ML\\\\project\\\\learning-to-parse-pdf\\\\documentAnalysis\\\\data\\\\images/PMC4527132_00004.jpg'}\n",
      "{'size': [794, 596], 'filepath': 'E:\\\\Google Drive\\\\Acads\\\\Notes\\\\final sem\\\\ML\\\\project\\\\learning-to-parse-pdf\\\\documentAnalysis\\\\data\\\\images/PMC4760359_00006.jpg'}\n",
      "{'size': [791, 596], 'filepath': 'E:\\\\Google Drive\\\\Acads\\\\Notes\\\\final sem\\\\ML\\\\project\\\\learning-to-parse-pdf\\\\documentAnalysis\\\\data\\\\images/PMC4954804_00001.jpg'}\n",
      "{'size': [794, 596], 'filepath': 'E:\\\\Google Drive\\\\Acads\\\\Notes\\\\final sem\\\\ML\\\\project\\\\learning-to-parse-pdf\\\\documentAnalysis\\\\data\\\\images/PMC4972521_00010.jpg'}\n",
      "{'size': [792, 612], 'filepath': 'E:\\\\Google Drive\\\\Acads\\\\Notes\\\\final sem\\\\ML\\\\project\\\\learning-to-parse-pdf\\\\documentAnalysis\\\\data\\\\images/PMC5302692_00002.jpg'}\n",
      "{'size': [842, 596], 'filepath': 'E:\\\\Google Drive\\\\Acads\\\\Notes\\\\final sem\\\\ML\\\\project\\\\learning-to-parse-pdf\\\\documentAnalysis\\\\data\\\\images/PMC5344221_00010.jpg'}\n",
      "{'size': [791, 596], 'filepath': 'E:\\\\Google Drive\\\\Acads\\\\Notes\\\\final sem\\\\ML\\\\project\\\\learning-to-parse-pdf\\\\documentAnalysis\\\\data\\\\images/PMC5432924_00001.jpg'}\n",
      "{'size': [794, 596], 'filepath': 'E:\\\\Google Drive\\\\Acads\\\\Notes\\\\final sem\\\\ML\\\\project\\\\learning-to-parse-pdf\\\\documentAnalysis\\\\data\\\\images/PMC5447509_00002.jpg'}\n",
      "{'size': [794, 596], 'filepath': 'E:\\\\Google Drive\\\\Acads\\\\Notes\\\\final sem\\\\ML\\\\project\\\\learning-to-parse-pdf\\\\documentAnalysis\\\\data\\\\images/PMC5491943_00004.jpg'}\n",
      "{'size': [791, 596], 'filepath': 'E:\\\\Google Drive\\\\Acads\\\\Notes\\\\final sem\\\\ML\\\\project\\\\learning-to-parse-pdf\\\\documentAnalysis\\\\data\\\\images/PMC5514520_00012.jpg'}\n",
      "{'size': [842, 596], 'filepath': 'E:\\\\Google Drive\\\\Acads\\\\Notes\\\\final sem\\\\ML\\\\project\\\\learning-to-parse-pdf\\\\documentAnalysis\\\\data\\\\images/PMC5590435_00004.jpg'}\n",
      "{'size': [842, 596], 'filepath': 'E:\\\\Google Drive\\\\Acads\\\\Notes\\\\final sem\\\\ML\\\\project\\\\learning-to-parse-pdf\\\\documentAnalysis\\\\data\\\\images/PMC5618295_00004.jpg'}\n",
      "{'size': [842, 596], 'filepath': 'E:\\\\Google Drive\\\\Acads\\\\Notes\\\\final sem\\\\ML\\\\project\\\\learning-to-parse-pdf\\\\documentAnalysis\\\\data\\\\images/PMC5624106_00000.jpg'}\n",
      "{'size': [791, 596], 'filepath': 'E:\\\\Google Drive\\\\Acads\\\\Notes\\\\final sem\\\\ML\\\\project\\\\learning-to-parse-pdf\\\\documentAnalysis\\\\data\\\\images/PMC5678782_00005.jpg'}\n"
     ]
    }
   ],
   "source": [
    "print('Total images', len(predictions))\n",
    "for i in range(len(predictions)):\n",
    "    print(predictions[i][0]['metadata'])\n",
    "    inp = (predictions[i][0]['input']).numpy().copy()\n",
    "    inp = np.transpose(inp, (1, 2, 0))\n",
    "    inp = cv2.resize(inp, (640, 800))\n",
    "    pred = (predictions[i][0]['preds'])\n",
    "    pred = torch.softmax(pred, dim = 0)\n",
    "    pred = torch.abs(pred)\n",
    "    pred = torch.argmax(pred, dim = 0).numpy().astype(np.uint8)\n",
    "    pred = cv2.resize(pred, (640, 800))\n",
    "    inp = (inp/np.max(inp) * 255).astype(np.uint8)\n",
    "    inp[:, :, 0][pred == 1] = 128\n",
    "    inp[:, :, 2][pred == 5] = 128\n",
    "    # inp[pred == 1] += 60\n",
    "    # inp[pred == 2] += 90\n",
    "    # inp[pred == 3] += 120\n",
    "    # inp[pred == 4] += 150\n",
    "    # inp[pred == 5] += 180\n",
    "    # inp[pred == 6] += 210\n",
    "    # inp[pred == 7] += 240\n",
    "\n",
    "    \n",
    "\n",
    "    b = inp\n",
    "    c =  (pred/np.max(pred) * 255).astype(np.uint8)\n",
    "    c = np.stack((c, c, c), axis = 2)\n",
    "    out = np.hstack(( b, c))\n",
    "    cv2.imwrite(f'preds/out_{i}.jpg', b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d5cf3276ec875bfd3a6dd7c9cd70bfefbf9f8fae75200921c59c75efcf9f9db2"
  },
  "kernelspec": {
   "display_name": "Python 3.6.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
