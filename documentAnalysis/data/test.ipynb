{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flash.image import SemanticSegmentation\n",
    "from flash.image import SemanticSegmentationData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from flash import Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 'efficientnet-b0' provided by qubvel/segmentation_models.pytorch (https://github.com/qubvel/segmentation_models.pytorch).\n",
      "Using 'unet' provided by qubvel/segmentation_models.pytorch (https://github.com/qubvel/segmentation_models.pytorch).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = SemanticSegmentation.load_from_checkpoint(r\"E:\\Google Drive\\Acads\\Notes\\final sem\\ML\\project\\learning-to-parse-pdf\\documentAnalysis\\flash\\semantic_segmentation_model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 7/7 [00:02<00:00,  3.11it/s]\n"
     ]
    }
   ],
   "source": [
    "dm = SemanticSegmentationData.from_folders(\n",
    "    predict_folder=r\"E:\\Google Drive\\Acads\\Notes\\final sem\\ML\\project\\learning-to-parse-pdf\\documentAnalysis\\data\\images/outofdata/\",\n",
    "    transform_kwargs=dict(image_size=(800, 640)),\n",
    "    batch_size = 1,\n",
    "    )\n",
    "trainer = Trainer(max_epochs=1, gpus = 1)\n",
    "predictions = trainer.predict(model, dm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images 7\n",
      "{'size': [1099, 720], 'filepath': 'E:\\\\Google Drive\\\\Acads\\\\Notes\\\\final sem\\\\ML\\\\project\\\\learning-to-parse-pdf\\\\documentAnalysis\\\\data\\\\images/outofdata/E4T1Za3VcAEPtMt.jpg'}\n",
      "{'size': [1650, 1275], 'filepath': 'E:\\\\Google Drive\\\\Acads\\\\Notes\\\\final sem\\\\ML\\\\project\\\\learning-to-parse-pdf\\\\documentAnalysis\\\\data\\\\images/outofdata/Indian Classical Music Synthesis_page-0002.jpg'}\n",
      "{'size': [1650, 1275], 'filepath': 'E:\\\\Google Drive\\\\Acads\\\\Notes\\\\final sem\\\\ML\\\\project\\\\learning-to-parse-pdf\\\\documentAnalysis\\\\data\\\\images/outofdata/Memory_Guided_Road_Segmentation___ICIAP_page-0005.jpg'}\n",
      "{'size': [380, 261], 'filepath': 'E:\\\\Google Drive\\\\Acads\\\\Notes\\\\final sem\\\\ML\\\\project\\\\learning-to-parse-pdf\\\\documentAnalysis\\\\data\\\\images/outofdata/NewsPaperTheHindu.jpg'}\n",
      "{'size': [1497, 1058], 'filepath': 'E:\\\\Google Drive\\\\Acads\\\\Notes\\\\final sem\\\\ML\\\\project\\\\learning-to-parse-pdf\\\\documentAnalysis\\\\data\\\\images/outofdata/TIMES-OF-INDIA-16-MAY-pdf (1).jpg'}\n",
      "{'size': [853, 657], 'filepath': 'E:\\\\Google Drive\\\\Acads\\\\Notes\\\\final sem\\\\ML\\\\project\\\\learning-to-parse-pdf\\\\documentAnalysis\\\\data\\\\images/outofdata/fixscan3.jpg'}\n",
      "{'size': [195, 259], 'filepath': 'E:\\\\Google Drive\\\\Acads\\\\Notes\\\\final sem\\\\ML\\\\project\\\\learning-to-parse-pdf\\\\documentAnalysis\\\\data\\\\images/outofdata/images.jpg'}\n"
     ]
    }
   ],
   "source": [
    "print('Total images', len(predictions))\n",
    "for i in range(len(predictions)):\n",
    "    print(predictions[i][0]['metadata'])\n",
    "    inp = (predictions[i][0]['input']).numpy().copy()\n",
    "    inp = np.transpose(inp, (1, 2, 0))\n",
    "    inp = cv2.resize(inp, (640, 800))\n",
    "    pred = (predictions[i][0]['preds'])\n",
    "    pred = torch.softmax(pred, dim = 0)\n",
    "    pred = torch.argmax(pred, dim = 0).numpy().astype(np.uint8)\n",
    "    pred = cv2.resize(pred, (640, 800))\n",
    "    inp = (inp/np.max(inp) * 255).astype(np.uint8)\n",
    "    inp[:, :, 0][pred == 1] = 128\n",
    "    inp[:, :, 1][pred == 2] = 128\n",
    "    inp[:, :, 2][pred == 3] = 128\n",
    "    inp[:, :, 1][pred == 4] = 55\n",
    "    inp[:, :, 2][pred == 5] = 55\n",
    "    inp[:, :, 0][pred == 6] = 55\n",
    "    inp[:, :, 1][pred == 7] = 200\n",
    "\n",
    "    b = inp\n",
    "    c =  (pred/np.max(pred) * 255).astype(np.uint8)\n",
    "    c = np.stack((c, c, c), axis = 2)\n",
    "    out = np.hstack(( b, c))\n",
    "    cv2.imwrite(f'preds/out_{i}.jpg', b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d5cf3276ec875bfd3a6dd7c9cd70bfefbf9f8fae75200921c59c75efcf9f9db2"
  },
  "kernelspec": {
   "display_name": "Python 3.6.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
